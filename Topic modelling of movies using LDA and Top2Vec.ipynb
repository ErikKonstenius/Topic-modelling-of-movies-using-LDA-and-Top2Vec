{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edd03f5",
   "metadata": {},
   "source": [
    "# Topic modelling of Amazon reviews using LDA and Top2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221cb62",
   "metadata": {},
   "source": [
    "This project is aimed to show how topic modelling works in practice using Top2Vec and LDA. \n",
    "\n",
    "The dataset contains plots of movies scraped from Wikipedia articles. It can downloaded from on https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cd237",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import gensim\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from top2vec import Top2Vec\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "pd.reset_option('^display.', silent=True)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee595cc5",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ef522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Erik Konstenius\\Downloads\\wiki_movie_plots_deduped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3274cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d356ecd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of movies: \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ab164",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique genres: \" + str(df[\"Genre\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe57dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, most movies belong to multiple genre\n",
    "\n",
    "for i in df[\"Genre\"].unique()[80:90]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723946b",
   "metadata": {},
   "source": [
    "Let's look at a couple of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717734d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df[[\"Title\",\"Plot\"]][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab991bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average length of movie plot: \" + str(round(df['Plot'].str.len().mean())) + \" words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2dfb4",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b0c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_pipeline(df, model):\n",
    "    # Remove stop words\n",
    "    df = df.apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in df:\n",
    "        review = re.sub('[^A-Za-z0-9-\" \"]+', '', review) #remove special characters\n",
    "        review = review.lower() #lower case words\n",
    "        reviews.append(re.sub(r'\\b\\w{1,2}\\b', '', review)) #remove short words\n",
    "    \n",
    "    if model == \"lda\":\n",
    "        output = [word_tokenize(sentence) for sentence in reviews]\n",
    "        temp = []\n",
    "        for movie in output: # Lemmatize each word\n",
    "            A = [stemmer.stem(WordNetLemmatizer().lemmatize(word, pos='v')) for word in movie]\n",
    "            temp.append(A)\n",
    "            \n",
    "        reviews = temp\n",
    "    \n",
    "    elif model == \"top2vec\":\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print(\"Model not recognized. Top2vec assumed\")\n",
    "    \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca71f0",
   "metadata": {},
   "source": [
    "# Applying Top2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b237736",
   "metadata": {},
   "source": [
    "Top2Vec is an algorithm for topic modeling and semantic search. The algorithm is an unsupervised machine learning technique that can find structure in the text that can be useful to organize data, search for similar text documents and possibly even work as a simple recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6d3a4",
   "metadata": {},
   "source": [
    "How the algorithm works:\n",
    "\n",
    "1. Create jointly embedded document and word vectors using Doc2Vec.\n",
    "\n",
    "2. Apply dimensionality reduction and convert a sparse dimensionalse vector space to a denser area of lower dimensional embeddings of text documents.\n",
    "\n",
    "3. Cluster dense areas of documents using HDBSCAN.\n",
    "\n",
    "4. For each dense area calculate the centroid of document vectors in original dimension. This centroid is the topic vector.\n",
    "\n",
    "5. Find n-closest word vectors to the resulting topic vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5429367",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pre_process_pipeline(df[\"Plot\"], model = \"top2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d715f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check corpus after cleaning\n",
    "\n",
    "corpus[100:103]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51743c12",
   "metadata": {},
   "source": [
    "Creating the Top2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec\n",
    "import tensorflow as tf\n",
    "model = Top2Vec(corpus, speed = 'deep-learn',  workers=12)\n",
    "\n",
    "# corpus: Input corpus, should be a list of strings.\n",
    "# speed: The ‘deep-learn’ option will learn the best quality vectors but will take significant time to train.\n",
    "# workers: The amount of worker threads to be used in training the model.\n",
    "\n",
    "# Warning: it can take multiple hours to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195df64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of detected topics.\n",
    "\n",
    "print(\"Number of topics: \" + str(model.get_num_topics()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea77638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the topics in decreasing size.\n",
    "\n",
    "topic_words, word_scores, topic_nums = model.get_topics(model.get_num_topics())\n",
    "\n",
    "# topic_words: For each topic the top 50 words are returned, in order of semantic similarity to topic.\n",
    "# word_scores: For each topic the cosine similarity scores of the top 50 words to the topic are returned.\n",
    "# topic_nums: The unique index of every topic will be returned.\n",
    "\n",
    "for topic in topic_nums:\n",
    "    model.generate_topic_wordcloud(topic)\n",
    "    \n",
    "# The results show that the technique has produced impressive segementation of the text data \n",
    "# stored in the movie plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a85ed",
   "metadata": {},
   "source": [
    "Next, I search for topics by a given keywor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79a099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"space\", \"planet\"],num_topics=3)\n",
    "\n",
    "# topic_words: For each topic the top 50 words are returned, in order of semantic similarity to topic.\n",
    "# word_scores: For each topic the cosine similarity scores of the top 50 words to the topic are returned.\n",
    "# topic_scores: For each topic the cosine similarity to the search keywords will be returned.\n",
    "# topic_nums: The unique index of every topic will be returned.\n",
    "\n",
    "for topic in topic_nums:\n",
    "    model.generate_topic_wordcloud(topic, background_color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"career\"],num_topics=3)\n",
    "\n",
    "# topic_words: For each topic the top 50 words are returned, in order of semantic similarity to topic.\n",
    "# word_scores: For each topic the cosine similarity scores of the top 50 words to the topic are returned.\n",
    "# topic_scores: For each topic the cosine similarity to the search keywords will be returned.\n",
    "# topic_nums: The unique index of every topic will be returned.\n",
    "\n",
    "for topic in topic_nums:\n",
    "    model.generate_topic_wordcloud(topic, background_color=\"black\")\n",
    "    \n",
    "# It appears to suggest topics within music, generael sports and boxing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ce98a",
   "metadata": {},
   "source": [
    "Next I search for topic and find documents with the highest similarity of document to a specified topic. For each of the returned documents we are going to print its content, score and document number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a16237",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=21, num_docs=5)\n",
    "\n",
    "# documents: The documents in a list, the most similar are first.\n",
    "# doc_scores: Semantic similarity of document to topic. The cosine similarity of the document and topic vector.\n",
    "# doc_ids: Unique ids of documents. If ids were not given, the index of document in the original corpus.\n",
    "    \n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\" \")\n",
    "    print(doc[0:500])\n",
    "    print(\" \")\n",
    "    \n",
    "# topic_num 21 appears to be about the nazis, jews and the Second World War. The movies suggested \n",
    "# fit the chosen topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb948c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=105, num_docs=5)\n",
    "\n",
    "# documents: The documents in a list, the most similar are first.\n",
    "# doc_scores: Semantic similarity of document to topic. The cosine similarity of the document and topic vector.\n",
    "# doc_ids: Unique ids of documents. If ids were not given, the index of document in the original corpus.\n",
    "    \n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\" \")\n",
    "    print(doc[0:500])\n",
    "    print(\" \")\n",
    "    \n",
    "# topic_num 105 appear to be about Harry Potter movies or similar movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5482307",
   "metadata": {},
   "source": [
    "# Applying LDA with BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0536279",
   "metadata": {},
   "source": [
    "How the algorithm works:\n",
    "\n",
    "\n",
    "1. Assess which word appear in each document. I will lemmatize, remove stop words and remove words that only appear in one document or are very common. This will be done using the bag-of-word technique where each word is assigned the number of times the word appears in corpus.\n",
    "\n",
    "\n",
    "2. Assess which words belong to each topic by looping over each word in each movie plot. This is done in the following steps:\n",
    "    \n",
    "    a) We loop through each movie plot an randomly assign a topic from a predefined set of topics.\n",
    "\n",
    "    b) We then loop through each word in each plot and compute the proportion of words in each   document that are assigned to each topic. If a lot of words from a movie plot belongs to a particular topic it is more probable that word belongs to the topic. We then calculate the how many times the word was assigned to the particular topic over the entire corpus. \n",
    " \n",
    "\n",
    "The end result is a model that considers every word in each document and determines how much that word is associated to each topic. If a word is associated more to a particular topic, then the document is more likely to be classified within that topic.\n",
    " \n",
    "\n",
    "Worth noting:\n",
    "1. We need to state in advance how many topics we want the model to filter the corpus in.\n",
    "2. Order of the words and the grammatical role of the words are not considered in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbac75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = pre_process_pipeline(df[\"Plot\"], model = \"lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7c714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The corpus is now also tokenized and lemmatized\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b40785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print just some of them\n",
    "\n",
    "len(corpus) # Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdcb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes words appearing in more than 0.5 % of the total corpus size\n",
    "\n",
    "corpus.filter_extremes(no_above=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cabb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus) # The filtering has removed a bit more than half of all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5236d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [bow.doc2bow(movie) for movie in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86deb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus = bow_corpus, num_topics=10, id2word=bow, passes=10, workers=12)\n",
    "\n",
    "# I restrict the model to only find 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4988895",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in range(lda_model.num_topics):\n",
    "    plt.figure(figsize=(40,5))\n",
    "    plt.imshow(WordCloud(width=800, height=400).fit_words(dict(lda_model.show_topic(topic, 300))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(topic))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6bdf4",
   "metadata": {},
   "source": [
    "# Applying LDA with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pre_process_pipeline(df[\"Plot\"], model = \"lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.filter_extremes(no_above=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb177e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [bow.doc2bow(movie) for movie in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tf-idf model\n",
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# Apply transformation to the entire corpus\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "lda_tfidf_model = gensim.models.LdaMulticore(corpus = corpus_tfidf, num_topics=10, id2word=bow, passes=10, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in range(lda_model.num_topics):\n",
    "    plt.figure(figsize=(40,5))\n",
    "    plt.imshow(WordCloud(width=800, height=400).fit_words(dict(lda_tfidf_model.show_topic(topic, 300))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(topic))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373c493",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b734e9",
   "metadata": {},
   "source": [
    "The Top2Vec outperformed both LDA models. Yet, in some situations it may be beneficial to be able to specify the number of topics when we know how many groups there are in the population. In this case, finding over 100 topics is maybe not very useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
